{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mllib package since we will use ML models\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "\n",
    "#global\n",
    "spam = None\n",
    "ham = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local config \n",
    "def local_code():\n",
    "    global spam\n",
    "    global ham\n",
    "    sc = None\n",
    "    os.environ['HADOOP_HOME'] = os.path.abspath(os.path.join(os.getcwd(), os.pardir)).replace('\\\\', '/')+'/util/hadoop-2.7.1'\n",
    "    while sc is None: \n",
    "        try: \n",
    "            sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local\"))\n",
    "        except: \n",
    "            pass\n",
    "    spam = sc.textFile(\"spam.txt\")\n",
    "    ham = sc.textFile(\"ham.txt\")\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws config \n",
    "def aws_code(): \n",
    "    global spam\n",
    "    global ham\n",
    "    spam = sc.textFile(\"s3://minghaohadoophw2/input/spam.txt\")\n",
    "    ham = sc.textFile(\"s3://minghaohadoophw2/input/ham.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<SparkContext master=local appName=pyspark-shell>"
      ],
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-HNLHSRI:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#environment config\n",
    "try: sc\n",
    "except NameError: sc = local_code()\n",
    "else: aws_code()\n",
    "#initiate a feature vector\n",
    "tf = HashingTF()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e4af8fc50e409f9eaf5aba2ad09445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#each email is split into words, each word is mapped to one feature\n",
    "#thus each email is mapped to a feature vector\n",
    "spamFeatures = spam.map(lambda email: tf.transform(email.split(\" \")))\n",
    "hamFeatures = ham.map(lambda email: tf.transform(email.split(\" \")))\n",
    "#for ML purpose (classifier), spam features are labeled as positive (1)\n",
    "#non-spam features are labeled as negative (0)\n",
    "positiveExamples = spamFeatures.map(lambda features: LabeledPoint(1, features))\n",
    "negativeExamples = hamFeatures.map(lambda features: LabeledPoint(0, features))\n",
    "#union spam and ham examples with labels now, for classifier\n",
    "training_data = positiveExamples.union(negativeExamples)\n",
    "#cache data since Logistic Regression is an iterative algorithm\n",
    "training_data.cache()\n",
    "#use ML model logistic regression with SGD method\n",
    "model = LogisticRegressionWithSGD.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035ce0ea93d94f0fb956be0024f2534e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for positive test example: 1\n",
      "Prediction for negative test example: 0"
     ]
    }
   ],
   "source": [
    "#testing: first transform test cases to words (features)\n",
    "posTestExample = tf.transform(\"O M G GET cheap stuff by sending money to ...\".split(\" \"))\n",
    "negTestExample = tf.transform(\"Hi Dad, I started studying Spark the other ...\".split(\" \"))\n",
    "#use classifier from training stage to predict the test cases\n",
    "print (\"Prediction for positive test example: %g\" % model.predict(posTestExample))\n",
    "print (\"Prediction for negative test example: %g\" % model.predict(negTestExample))\n",
    "#call stop function from SparkContext to clean up resources\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c627be1547c7c874688ddee1aaaa67b367275f1752d282bff5eb427acd241334"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}